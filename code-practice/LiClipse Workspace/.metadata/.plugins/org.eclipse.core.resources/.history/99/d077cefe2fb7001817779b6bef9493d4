
import os
from pip._vendor.distlib.util import _external_data_base_url
from matplotlib import _mathtext_data


# each website you crawl is a separate project (folder)

def create_project_directory(directory):
    if not os.path.exists(directory):
        print("Creating project : " , directory)
        os.makedirs(directory)
        

create_project_directory('thenewboston')

# Create queue and crawled files

def creat_data_files(project_name, base_url):
  queue = project_name + 'queue.txt'
  crawled = project_name + 'crawled.txt'
  if not os.path.isfile(queue):
      write_file(queue, base_url)
  if not os.path.isfile(crawled):
      write_file(crawled, '')
     

# Create a new file

def write_file(path, data):
    f = open(path, 'w')
    f.write(data)
    f.cloe()
    
